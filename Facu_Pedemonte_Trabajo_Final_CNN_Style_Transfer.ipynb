{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facu Pedemonte - Trabajo Final CNN - Style Transfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FPedemonte/Trabajo-Final-CV/blob/main/Facu_Pedemonte_Trabajo_Final_CNN_Style_Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCY6UbkkI9_N"
      },
      "source": [
        "# Style Transfer\n",
        "\n",
        "<img src=\"https://i0.wp.com/chelseatroy.com/wp-content/uploads/2018/12/neural_style_transfer.png?resize=768%2C311&ssl=1\">\n",
        "\n",
        "La idea de este trabajo final es reproducir el siguiente paper:\n",
        "\n",
        "https://arxiv.org/pdf/1508.06576.pdf\n",
        "\n",
        "El objetivo es transferir el estilo de una imagen dada a otra imagen distinta. \n",
        "\n",
        "Como hemos visto en clase, las primeras capas de una red convolucional se activan ante la presencia de ciertos patrones vinculados a detalles muy pequeños.\n",
        "\n",
        "A medida que avanzamos en las distintas capas de una red neuronal convolucional, los filtros se van activando a medida que detectan patrones de formas cada vez mas complejos.\n",
        "\n",
        "Lo que propone este paper es asignarle a la activación de las primeras capas de una red neuronal convolucional (por ejemplo VGG19) la definición del estilo y a la activación de las últimas capas de la red neuronal convolucional, la definición del contenido.\n",
        "\n",
        "La idea de este paper es, a partir de dos imágenes (una que aporte el estilo y otra que aporte el contenido) analizar cómo es la activación de las primeras capas para la imagen que aporta el estilo y cómo es la activación de las últimas capas de la red convolucional para la imagen que aporta el contenido. A partir de esto se intentará sintetizar una imagen que active los filtros de las primeras capas que se activaron con la imagen que aporta el estilo y los filtros de las últimas capas que se activaron con la imagen que aporta el contenido.\n",
        "\n",
        "A este procedimiento se lo denomina neural style transfer.\n",
        "\n",
        "# En este trabajo se deberá leer el paper mencionado y en base a ello, entender la implementación que se muestra a continuación y contestar preguntas sobre la misma.\n",
        "\n",
        "# Una metodología posible es hacer una lectura rápida del paper (aunque esto signifique no entender algunos detalles del mismo) y luego ir analizando el código y respondiendo las preguntas. A medida que se planteen las preguntas, volviendo a leer secciones específicas del paper terminará de entender los detalles que pudieran haber quedado pendientes.\n",
        "\n",
        "Lo primero que haremos es cargar dos imágenes, una que aporte el estilo y otra que aporte el contenido. A tal fin utilizaremos imágenes disponibles en la web."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyHsa2t0SxZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a570689-63ce-449c-c939-b38e6f4e3d25"
      },
      "source": [
        "# Imagen para estilo\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
        "\n",
        "# Imagen para contenido\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
        "\n",
        "# Creamos el directorio para los archivos de salida\n",
        "!mkdir /content/output"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-30 22:32:12--  https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.153.240, 2620:0:860:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.153.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 223725 (218K) [image/jpeg]\n",
            "Saving to: ‘La_noche_estrellada1.jpg’\n",
            "\n",
            "La_noche_estrellada 100%[===================>] 218.48K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-09-30 22:32:12 (1.52 MB/s) - ‘La_noche_estrellada1.jpg’ saved [223725/223725]\n",
            "\n",
            "--2021-09-30 22:32:12--  https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.153.240, 2620:0:860:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.153.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 153015 (149K) [image/jpeg]\n",
            "Saving to: ‘775px-Neckarfront_Tübingen_Mai_2017.jpg’\n",
            "\n",
            "775px-Neckarfront_T 100%[===================>] 149.43K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-09-30 22:32:12 (1.24 MB/s) - ‘775px-Neckarfront_Tübingen_Mai_2017.jpg’ saved [153015/153015]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIxH20o2eFoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "248a7a09-6604-411d-912d-5d2740bf6b84"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
        "import numpy as np\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "import time\n",
        "import argparse\n",
        "\n",
        "from keras.applications import vgg19\n",
        "from keras import backend as K\n",
        "from pathlib import Path"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLkV1bnFl_tK"
      },
      "source": [
        "# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n",
        "\n",
        "# base_image_path = Path(\"/content/775px-Neckarfront_Tübingen_Mai_2017.jpg\")\n",
        "# style_reference_image_path = Path(\"/content/La_noche_estrellada1.jpg\")\n",
        "base_image_path = Path(\"/content/Contacto ET.jpeg\")\n",
        "style_reference_image_path = Path(\"/content/Girasoles 2.png\")\n",
        "\n",
        "result_prefix = Path(\"/content/output\")\n",
        "iterations = 50\n",
        "\n"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz2PeGfpeYzj"
      },
      "source": [
        "# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?\n",
        "\n",
        "Respuesta:  \n",
        "- *style_weight* corresponde al énfasis con que la imagen resultante será coincidente con el estilo extraído de la imagen de estilo; \n",
        "- *content_weight* por otro lado, es la intensidad con que la imagen resultante matcheará el contenido de la imagen de contenido; \n",
        "- *total_variation_weight* define el nivel de incidencia de la loss de regularización, y por tanto, cuan \"smootheada\" resultará la imagen generada.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9Dt3aaEmJWS"
      },
      "source": [
        "total_variation_weight = 0.1\n",
        "style_weight = 10\n",
        "content_weight = 1"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQJOhCVuse6"
      },
      "source": [
        "# Definimos el tamaño de las imágenes a utilizar\n",
        "width, height = load_img(base_image_path).size\n",
        "img_nrows = 400\n",
        "img_ncols = int(width * img_nrows / height)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg2ct-8agm1E"
      },
      "source": [
        "# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué?\n",
        "\n",
        "Ayuda: https://keras.io/applications/\n",
        "\n",
        "Respuesta: esta celda realiza un preprocesamiento sobre la imagen de entrada antes de introducirla al modelo, el cual es un requerimiento de las aplicaciones de Keras. Las últimas dos líneas de la función antes del return generan lo siguiente: añaden una dimensión a img para dar cuenta del batch number; y luego convierte la imagen de entrada de RGB a BFR, centrando en cero cada canal de color con respecto al dataset de ImageNet, sin escalar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAkljg4zuzYd"
      },
      "source": [
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = vgg19.preprocess_input(img)\n",
        "    return img"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTf0YDSagt10"
      },
      "source": [
        "# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n",
        "\n",
        "Respuesta: postprocesa la imagen x para recuperar las características perdidas al preprocesar de la manera en que lo requiere la VGG19 de Keras. Es decir, elimina la dimensión correspondiente al batch, remueve el centrado en cero y convierte la imagen de BGR a RGB."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5LaTrsAu14z"
      },
      "source": [
        "def deprocess_image(x):\n",
        "    x = x.reshape((img_nrows, img_ncols, 3))\n",
        "    # Remove zero-center by mean pixel\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    # 'BGR'->'RGB'\n",
        "    x = x[:, :, ::-1]\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYNio09mu4S3"
      },
      "source": [
        "# get tensor representations of our images\n",
        "# K.variable convierte un numpy array en un tensor, para \n",
        "base_image = K.variable(preprocess_image(base_image_path))\n",
        "style_reference_image = K.variable(preprocess_image(style_reference_image_path))"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Lbw02Uu--o"
      },
      "source": [
        "combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJEi0YI3Uzrm"
      },
      "source": [
        "Aclaración:\n",
        "\n",
        "La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGO_jGFfvEbF"
      },
      "source": [
        "# combine the 3 images into a single Keras tensor\n",
        "input_tensor = K.concatenate([base_image,\n",
        "                              style_reference_image,\n",
        "                              combination_image], axis=0)"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdG59VRavHGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ab57fe-8572-418e-c195-79ac9e53d7d1"
      },
      "source": [
        "# build the VGG19 network with our 3 images as input\n",
        "# the model will be loaded with pre-trained ImageNet weights\n",
        "model = vgg19.VGG19(input_tensor=input_tensor,\n",
        "                    weights='imagenet', include_top=False)\n",
        "print('Model loaded.')\n",
        "\n",
        "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70-vs_jZkKVc"
      },
      "source": [
        "# 4) En la siguientes celdas:\n",
        "\n",
        "- ¿Qué es la matriz de Gram?¿Para qué se usa?: La matriz de Gram representa el estilo de la imagen con que se construye. Se arma obteniendo el producto punto entre todas las permutaciones de las columnas de la matriz x, siendo cada columna de esa matriz un filtro convolucional \"flattened\" de la capa de estilo. \n",
        "Se utiliza para construir la style_loss.\n",
        "\n",
        "- ¿Por qué se permutan las dimensiones de x?: Para poder calcular la matriz de Gram mediante producto de matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1FODPATvJ1k"
      },
      "source": [
        "def gram_matrix(x):\n",
        "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "    gram = K.dot(features, K.transpose(features))\n",
        "    return gram"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBQkKFY0Rbx-"
      },
      "source": [
        "# 5) Losses:\n",
        "\n",
        "Explicar qué mide cada una de las losses en las siguientes tres celdas.\n",
        "\n",
        "Rta: \n",
        "- *style_loss*: mide la diferencia o distancia de los features de estilo (por ejemplo, textura) entre la imagen de estilo y la imagen generada.\n",
        "- *content_loss*: mide la diferencia o distancia de los features de contenido (características de alto nivel, la macroestructura) entre la imagen de contenido y la imagen generada.\n",
        "- *total_variation_loss*: es una loss de regularización, para lograr coherencia local en la imagen generada (suaviza la variación entre píxeles vecinos)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Gt0ahWvN6q"
      },
      "source": [
        "def style_loss(style, combination):\n",
        "    assert K.ndim(style) == 3\n",
        "    assert K.ndim(combination) == 3\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = img_nrows * img_ncols\n",
        "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCqnju5RvQCo"
      },
      "source": [
        "def content_loss(base, combination):\n",
        "    return K.sum(K.square(combination - base))\n"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udEp5h31vRnY"
      },
      "source": [
        "def total_variation_loss(x):\n",
        "    assert K.ndim(x) == 4\n",
        "    a = K.square(\n",
        "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
        "    b = K.square(\n",
        "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
        "    return K.sum(K.pow(a + b, 1.25))\n"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-65vcinbvTZ0"
      },
      "source": [
        "# Armamos la loss total\n",
        "loss = K.variable(0.0)\n",
        "layer_features = outputs_dict['block5_conv2']\n",
        "base_image_features = layer_features[0, :, :, :]\n",
        "combination_features = layer_features[2, :, :, :]\n",
        "loss = loss + content_weight * content_loss(base_image_features,\n",
        "                                            combination_features)\n",
        "\n",
        "feature_layers = ['block1_conv1', 'block2_conv1',\n",
        "                  'block3_conv1', 'block4_conv1',\n",
        "                  'block5_conv1']\n",
        "for layer_name in feature_layers:\n",
        "    layer_features = outputs_dict[layer_name]\n",
        "    style_reference_features = layer_features[1, :, :, :] \n",
        "    combination_features = layer_features[2, :, :, :]\n",
        "    sl = style_loss(style_reference_features, combination_features)\n",
        "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
        "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbz4n1OhvV2K"
      },
      "source": [
        "grads = K.gradients(loss, combination_image)\n",
        "\n",
        "outputs = [loss]\n",
        "if isinstance(grads, (list, tuple)):\n",
        "    outputs += grads\n",
        "else:\n",
        "    outputs.append(grads)\n",
        "\n",
        "f_outputs = K.function([combination_image], outputs)"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JbydbOaVcvU"
      },
      "source": [
        "# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n",
        "\n",
        "Respuesta: Las tres celdas siguientes iteran n veces el proceso de optimización para lograr generar imágenes que se acerquen cada vez más al resultado deseado.\n",
        "La función fmin_l_bfgs_b minimiza una función \"func\" empleando el algoritmo L-BFGS-B (algoritmo de optimización que aproxima el algoritmo de Broyden-Fletcher-Goldfarb-Shanno empleando una cantidad limitada de memoria). \n",
        "Se diferencia de la implementación del paper en que en él se optimizó empleando descenso de gradiente. \n",
        "Como alternativa se podría utilizar, por ejemplo, Adam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVE1_qemvZeN"
      },
      "source": [
        "def eval_loss_and_grads(x):\n",
        "    x = x.reshape((1, img_nrows, img_ncols, 3))\n",
        "    outs = f_outputs([x])\n",
        "    loss_value = outs[0]\n",
        "    if len(outs[1:]) == 1:\n",
        "        grad_values = outs[1].flatten().astype('float64')\n",
        "    else:\n",
        "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
        "    return loss_value, grad_values\n",
        "\n",
        "# this Evaluator class makes it possible\n",
        "# to compute loss and gradients in one pass\n",
        "# while retrieving them via two separate functions,\n",
        "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
        "# requires separate functions for loss and gradients,\n",
        "# but computing them separately would be inefficient."
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbl9roIgvdb1"
      },
      "source": [
        "class Evaluator(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.loss_value = None\n",
        "        self.grads_values = None\n",
        "\n",
        "    def loss(self, x):\n",
        "        assert self.loss_value is None\n",
        "        loss_value, grad_values = eval_loss_and_grads(x)\n",
        "        self.loss_value = loss_value\n",
        "        self.grad_values = grad_values\n",
        "        return self.loss_value\n",
        "\n",
        "    def grads(self, x):\n",
        "        assert self.loss_value is not None\n",
        "        grad_values = np.copy(self.grad_values)\n",
        "        self.loss_value = None\n",
        "        self.grad_values = None\n",
        "        return grad_values"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb0yOEl-WOE6"
      },
      "source": [
        "# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n31YBwCVvhAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f72a520-0217-44f4-b074-ba5e39ee0059"
      },
      "source": [
        "evaluator = Evaluator()\n",
        "\n",
        "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
        "# so as to minimize the neural style loss\n",
        "x = preprocess_image(base_image_path)\n",
        "\n",
        "for i in range(iterations):\n",
        "    print('Start of iteration', i)\n",
        "    start_time = time.time()\n",
        "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
        "                                     fprime=evaluator.grads, maxfun=20)\n",
        "    print('Current loss value:', min_val)\n",
        "    # save current generated image\n",
        "    img = deprocess_image(x.copy())\n",
        "    fname = result_prefix / ('output_at_iteration_%d.png' % i)\n",
        "    save_img(fname, img)\n",
        "    end_time = time.time()\n",
        "    print('Image saved as', fname)\n",
        "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start of iteration 0\n",
            "Current loss value: 49637896000.0\n",
            "Image saved as /content/output/output_at_iteration_0.png\n",
            "Iteration 0 completed in 16s\n",
            "Start of iteration 1\n",
            "Current loss value: 23539636000.0\n",
            "Image saved as /content/output/output_at_iteration_1.png\n",
            "Iteration 1 completed in 15s\n",
            "Start of iteration 2\n",
            "Current loss value: 17560496000.0\n",
            "Image saved as /content/output/output_at_iteration_2.png\n",
            "Iteration 2 completed in 15s\n",
            "Start of iteration 3\n",
            "Current loss value: 13842781000.0\n",
            "Image saved as /content/output/output_at_iteration_3.png\n",
            "Iteration 3 completed in 15s\n",
            "Start of iteration 4\n",
            "Current loss value: 11673601000.0\n",
            "Image saved as /content/output/output_at_iteration_4.png\n",
            "Iteration 4 completed in 15s\n",
            "Start of iteration 5\n",
            "Current loss value: 10080085000.0\n",
            "Image saved as /content/output/output_at_iteration_5.png\n",
            "Iteration 5 completed in 15s\n",
            "Start of iteration 6\n",
            "Current loss value: 8945821000.0\n",
            "Image saved as /content/output/output_at_iteration_6.png\n",
            "Iteration 6 completed in 15s\n",
            "Start of iteration 7\n",
            "Current loss value: 8030057500.0\n",
            "Image saved as /content/output/output_at_iteration_7.png\n",
            "Iteration 7 completed in 15s\n",
            "Start of iteration 8\n",
            "Current loss value: 7286596000.0\n",
            "Image saved as /content/output/output_at_iteration_8.png\n",
            "Iteration 8 completed in 15s\n",
            "Start of iteration 9\n",
            "Current loss value: 6728712700.0\n",
            "Image saved as /content/output/output_at_iteration_9.png\n",
            "Iteration 9 completed in 15s\n",
            "Start of iteration 10\n",
            "Current loss value: 6242457600.0\n",
            "Image saved as /content/output/output_at_iteration_10.png\n",
            "Iteration 10 completed in 15s\n",
            "Start of iteration 11\n",
            "Current loss value: 5891761700.0\n",
            "Image saved as /content/output/output_at_iteration_11.png\n",
            "Iteration 11 completed in 15s\n",
            "Start of iteration 12\n",
            "Current loss value: 5538936300.0\n",
            "Image saved as /content/output/output_at_iteration_12.png\n",
            "Iteration 12 completed in 15s\n",
            "Start of iteration 13\n",
            "Current loss value: 5248147500.0\n",
            "Image saved as /content/output/output_at_iteration_13.png\n",
            "Iteration 13 completed in 15s\n",
            "Start of iteration 14\n",
            "Current loss value: 4949946000.0\n",
            "Image saved as /content/output/output_at_iteration_14.png\n",
            "Iteration 14 completed in 15s\n",
            "Start of iteration 15\n",
            "Current loss value: 4694479400.0\n",
            "Image saved as /content/output/output_at_iteration_15.png\n",
            "Iteration 15 completed in 15s\n",
            "Start of iteration 16\n",
            "Current loss value: 4481821000.0\n",
            "Image saved as /content/output/output_at_iteration_16.png\n",
            "Iteration 16 completed in 15s\n",
            "Start of iteration 17\n",
            "Current loss value: 4308916000.0\n",
            "Image saved as /content/output/output_at_iteration_17.png\n",
            "Iteration 17 completed in 15s\n",
            "Start of iteration 18\n",
            "Current loss value: 4145461800.0\n",
            "Image saved as /content/output/output_at_iteration_18.png\n",
            "Iteration 18 completed in 15s\n",
            "Start of iteration 19\n",
            "Current loss value: 3962376000.0\n",
            "Image saved as /content/output/output_at_iteration_19.png\n",
            "Iteration 19 completed in 15s\n",
            "Start of iteration 20\n",
            "Current loss value: 3815397400.0\n",
            "Image saved as /content/output/output_at_iteration_20.png\n",
            "Iteration 20 completed in 15s\n",
            "Start of iteration 21\n",
            "Current loss value: 3664966700.0\n",
            "Image saved as /content/output/output_at_iteration_21.png\n",
            "Iteration 21 completed in 15s\n",
            "Start of iteration 22\n",
            "Current loss value: 3539363300.0\n",
            "Image saved as /content/output/output_at_iteration_22.png\n",
            "Iteration 22 completed in 15s\n",
            "Start of iteration 23\n",
            "Current loss value: 3389125600.0\n",
            "Image saved as /content/output/output_at_iteration_23.png\n",
            "Iteration 23 completed in 16s\n",
            "Start of iteration 24\n",
            "Current loss value: 3270203600.0\n",
            "Image saved as /content/output/output_at_iteration_24.png\n",
            "Iteration 24 completed in 15s\n",
            "Start of iteration 25\n",
            "Current loss value: 3139566300.0\n",
            "Image saved as /content/output/output_at_iteration_25.png\n",
            "Iteration 25 completed in 15s\n",
            "Start of iteration 26\n",
            "Current loss value: 3025697800.0\n",
            "Image saved as /content/output/output_at_iteration_26.png\n",
            "Iteration 26 completed in 15s\n",
            "Start of iteration 27\n",
            "Current loss value: 2953110300.0\n",
            "Image saved as /content/output/output_at_iteration_27.png\n",
            "Iteration 27 completed in 15s\n",
            "Start of iteration 28\n",
            "Current loss value: 2864862500.0\n",
            "Image saved as /content/output/output_at_iteration_28.png\n",
            "Iteration 28 completed in 15s\n",
            "Start of iteration 29\n",
            "Current loss value: 2788481500.0\n",
            "Image saved as /content/output/output_at_iteration_29.png\n",
            "Iteration 29 completed in 15s\n",
            "Start of iteration 30\n",
            "Current loss value: 2727634400.0\n",
            "Image saved as /content/output/output_at_iteration_30.png\n",
            "Iteration 30 completed in 15s\n",
            "Start of iteration 31\n",
            "Current loss value: 2675278600.0\n",
            "Image saved as /content/output/output_at_iteration_31.png\n",
            "Iteration 31 completed in 15s\n",
            "Start of iteration 32\n",
            "Current loss value: 2576499200.0\n",
            "Image saved as /content/output/output_at_iteration_32.png\n",
            "Iteration 32 completed in 15s\n",
            "Start of iteration 33\n",
            "Current loss value: 2504749600.0\n",
            "Image saved as /content/output/output_at_iteration_33.png\n",
            "Iteration 33 completed in 15s\n",
            "Start of iteration 34\n",
            "Current loss value: 2457775600.0\n",
            "Image saved as /content/output/output_at_iteration_34.png\n",
            "Iteration 34 completed in 15s\n",
            "Start of iteration 35\n",
            "Current loss value: 2410568200.0\n",
            "Image saved as /content/output/output_at_iteration_35.png\n",
            "Iteration 35 completed in 15s\n",
            "Start of iteration 36\n",
            "Current loss value: 2356065300.0\n",
            "Image saved as /content/output/output_at_iteration_36.png\n",
            "Iteration 36 completed in 15s\n",
            "Start of iteration 37\n",
            "Current loss value: 2311738600.0\n",
            "Image saved as /content/output/output_at_iteration_37.png\n",
            "Iteration 37 completed in 15s\n",
            "Start of iteration 38\n",
            "Current loss value: 2275783200.0\n",
            "Image saved as /content/output/output_at_iteration_38.png\n",
            "Iteration 38 completed in 15s\n",
            "Start of iteration 39\n",
            "Current loss value: 2227686700.0\n",
            "Image saved as /content/output/output_at_iteration_39.png\n",
            "Iteration 39 completed in 15s\n",
            "Start of iteration 40\n",
            "Current loss value: 2182018000.0\n",
            "Image saved as /content/output/output_at_iteration_40.png\n",
            "Iteration 40 completed in 15s\n",
            "Start of iteration 41\n",
            "Current loss value: 2134851500.0\n",
            "Image saved as /content/output/output_at_iteration_41.png\n",
            "Iteration 41 completed in 15s\n",
            "Start of iteration 42\n",
            "Current loss value: 2094364500.0\n",
            "Image saved as /content/output/output_at_iteration_42.png\n",
            "Iteration 42 completed in 15s\n",
            "Start of iteration 43\n",
            "Current loss value: 2052324400.0\n",
            "Image saved as /content/output/output_at_iteration_43.png\n",
            "Iteration 43 completed in 15s\n",
            "Start of iteration 44\n",
            "Current loss value: 2015853200.0\n",
            "Image saved as /content/output/output_at_iteration_44.png\n",
            "Iteration 44 completed in 15s\n",
            "Start of iteration 45\n",
            "Current loss value: 1988864500.0\n",
            "Image saved as /content/output/output_at_iteration_45.png\n",
            "Iteration 45 completed in 15s\n",
            "Start of iteration 46\n",
            "Current loss value: 1960239100.0\n",
            "Image saved as /content/output/output_at_iteration_46.png\n",
            "Iteration 46 completed in 15s\n",
            "Start of iteration 47\n",
            "Current loss value: 1933167500.0\n",
            "Image saved as /content/output/output_at_iteration_47.png\n",
            "Iteration 47 completed in 15s\n",
            "Start of iteration 48\n",
            "Current loss value: 1905223800.0\n",
            "Image saved as /content/output/output_at_iteration_48.png\n",
            "Iteration 48 completed in 15s\n",
            "Start of iteration 49\n",
            "Current loss value: 1881960800.0\n",
            "Image saved as /content/output/output_at_iteration_49.png\n",
            "Iteration 49 completed in 15s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9qAdmRJ6-Cc",
        "outputId": "03ce2a90-c44d-4fd5-ba0c-ef71173ffc8e"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkiJtofbWWy1"
      },
      "source": [
        "# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n",
        "\n",
        "Respuesta:\n",
        "\n",
        "\n",
        "(0) tv = 0.1; sw = 10; cw = 1\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1bER1nlD7yzHFwgwfr6qD35BRjQacjCYl)\n",
        "\n",
        "-----------------------------\n",
        "\n",
        "(1) tv = 100; sw = 10; cw = 1\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=11rmc8jprIW-IRqlv220XUUTqNzdAtQHh)\n",
        "\n",
        "En este caso, en comparación con la imagen de referencia (caso 0) el aumento del peso de la loss de regularización generó un efecto de smootheado, o incremento de la coherencia de los colores de los píxeles vecinos.\n",
        "\n",
        "-----------------------\n",
        "\n",
        "(2) tv = 1; sw = 10; cw = 0.1\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1fDk7C1yl9tHUV_CI1O1pNXeXVBiWIPZT)\n",
        "\n",
        "Este set de parámetros generó una imagen con mucho mayor contenido de \"estilo\" que la imagen generada en el apartado \"0\". Esto se debe al aumento del peso de la loss de estilo frente al de la de contenido.\n",
        "\n",
        "--------------------------\n",
        "\n",
        "(3) tv = 1; sw = 10; cw = 100\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1X-5011okO5P8l9POkqQxhLMzkQ2Rd60Y)\n",
        "\n",
        "Finalmente, este set de parámetros generó una imagen que conserva más contenido que las imágenes anteriores, debido a que el peso de la loss de contenido fue elevado con respecto al de la loss de estilo.\n",
        "\n",
        "\n",
        "\n",
        "# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n",
        "\n",
        "Respuesta:\n",
        "\n",
        "Contenido:\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1fDVTCVsJ8wuAd7EZjnJzT8MUV3exrvCc)\n",
        "\n",
        "Estilo:\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1hxB9cZmo8D7OLcFa15ySbl67oBu1iBI4)\n",
        "\n",
        "Resultado:\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1Z4j9njP4yaWCzoxLX3BZzlaj2bNTuC0c)\n",
        "\n"
      ]
    }
  ]
}